{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Import Modules\n",
    "import datetime\n",
    "import itertools\n",
    "#import graphviz\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import xgboost\n",
    "\n",
    "# Other Imports\n",
    "from matplotlib import rcParams, gridspec\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Keras Imports\n",
    "from keras import models, layers\n",
    "from keras import regularizers\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Embedding\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# Preprocesing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sklearn Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report,\n",
    "                             f1_score, precision_score, recall_score,\n",
    "                             precision_recall_fscore_support, roc_auc_score)\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import (cross_val_score, KFold, train_test_split,\n",
    "                                     GridSearchCV, cross_validate,\n",
    "                                     StratifiedKFold)\n",
    "\n",
    "# Set Numpy and Python Random Seed\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Pandas Configuration\n",
    "pd.set_option('max_columns', 1000)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Warning Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting Configuration\n",
    "rcParams['figure.figsize'] = (12.0, 4.0)\n",
    "rcParams.update({'font.size': 10})\n",
    "colors = ['#74a9cf', '#6a51a3']\n",
    "\n",
    "# Print versions of each package above \n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Sklearn version: {}\".format(sklearn.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "print(\"XBG Boost version: {}\".format(xgboost.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def anon_to_target(array):\n",
    "    '''\n",
    "    Converts Prediction in the +1/-1 format to 0/1 format for every value in the array\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    array: numpy array containing only +1/1\n",
    "\n",
    "    Exmaples\n",
    "    ---------\n",
    "    >>>> anon_to_targets([1,1,,1,1,-1,1,-1,1])\n",
    "    '''\n",
    "\n",
    "    array = [0 if i == 1 else 1 for i in array]\n",
    "    array = np.array(array).reshape(1, -1)[0]\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "def grid_search_groupby(results: pd.DataFrame, param_1: str, param_2: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Create a aggregated dataframe from the grid search results use the two\n",
    "    hyper paramters that we pass into the function. We will be using this\n",
    "    function to plot heatmaps from our grid search.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results: DataFrame of Grid Score results.\n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    >>> (grid_search_groupby(results,'max_depth','n_estimators')\n",
    "    >>> grid_search_groupby(results,'max_leaf_nodes','n_estimators')\n",
    "    '''\n",
    "    assert (type(results) ==  type(pd.DataFrame())), 'results should be a pandas.core.frame.DataFrame'\n",
    "    assert (type(param_1) == str), 'param_1 should be a string'\n",
    "    assert (type(param_2) == str), 'param_2 should be a string'\n",
    "\n",
    "    params_df  = pd.DataFrame.from_dict(list(results.params.values))\n",
    "    mean_test_score = results.mean_test_score\n",
    "    result_shrt_df = pd.concat([mean_test_score, params_df], axis=1)\n",
    "    result_shrt_df = result_shrt_df.fillna(value='None') # Fill in Default value None with string\n",
    "    result_groupby = result_shrt_df.groupby([param_1, param_2])['mean_test_score'].mean().unstack()\n",
    "    return result_groupby\n",
    "\n",
    "\n",
    "def plot_confusion_anomoly(model, classes, name,\n",
    "                           train_y, test_y, train_x,test_x,\n",
    "                           cmap=plt.cm.Purples):\n",
    "    '''\n",
    "    Function plots a confusion matrix given train and test \n",
    "    unsuperived models\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_model: sklearn/keras model object to be trained on training data\n",
    "    test_moedl: sklearn/keras model object to be trained on test data\n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    >>>> plot_confusion_anomoly(xg_model, train_x, train_y)\n",
    "    >>>> plot_confusion_anomoly(rf_model, train_x, train_y)\n",
    "    '''\n",
    "    rcParams['figure.figsize'] = (30.0, 22.5)\n",
    "\n",
    "    # Plot Train Confusion Matrix\n",
    "    fig = gridspec.GridSpec(3,3)\n",
    "    grid_length = list(range(1,3))\n",
    "    tuple_grid = [(i,j) for i in grid_length for j in grid_length]\n",
    "\n",
    "    plt.subplot2grid((3,3), (0,0))\n",
    "    cm = confusion_matrix(train_y, anon_to_target(model.predict(train_x)))\n",
    "    plot_confusion_matrix(cm, classes, fontsize=20, \n",
    "                          title=name,\n",
    "                         normalize=True, cmap=cmap)\n",
    "    \n",
    "    plt.subplot2grid((3,3), (0,1))\n",
    "    cm = confusion_matrix(test_y, anon_to_target(model.predict(test_x)))\n",
    "    plot_confusion_matrix(cm, classes, fontsize=20,\n",
    "                          title=name,\n",
    "                         normalize=True, cmap=cmap);\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, fontsize=20,\n",
    "                          normalize=False, title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    THE MAIN CONFUSION MATRIX, KAVI DON'T DELTETE BY ACCIDENT AGAIN. Function plots a \n",
    "    confusion matrix given a cm matrix and class names\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: sklearn confusion matrix\n",
    "    classes: numpy 1D array containing all unique class names\n",
    "\n",
    "    Examples\n",
    "    ---------\n",
    "    >>>>\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "    cm,\n",
    "    classes,\n",
    "    fontsize=25,\n",
    "    normalize=True,\n",
    "    title=model.name.capitalize() + ': Test Set',\n",
    "    cmap=plt.cm.Greens)\n",
    "\n",
    "    '''\n",
    "    cm_num = cm\n",
    "    cm_per = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        # print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        None\n",
    "        # print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title.replace('_',' ').title()+'\\n', size=fontsize)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size=fontsize)\n",
    "    plt.yticks(tick_marks, classes, size=fontsize)\n",
    "\n",
    "    fmt = '.5f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        # Set color parameters\n",
    "        color = \"white\" if cm[i, j] > thresh else \"black\"\n",
    "        alignment = \"center\"\n",
    "\n",
    "        # Plot perentage\n",
    "        text = format(cm_per[i, j], '.5f')\n",
    "        text = text + '%'\n",
    "        plt.text(j, i,\n",
    "            text,\n",
    "            fontsize=fontsize,\n",
    "            verticalalignment='baseline',\n",
    "            horizontalalignment='center',\n",
    "            color=color)\n",
    "        # Plot numeric\n",
    "        text = format(cm_num[i, j], 'd')\n",
    "        text = '\\n \\n' + text\n",
    "        plt.text(j, i,\n",
    "            text,\n",
    "            fontsize=fontsize,\n",
    "            verticalalignment='center',\n",
    "            horizontalalignment='center',\n",
    "            color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label'.title(), size=fontsize)\n",
    "    plt.xlabel('Predicted label'.title(), size=fontsize)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def plot_confusion_normal(model, classes, name, train_x, train_y,\n",
    "                          test_x, test_y, cmap=plt.cm.Greens):\n",
    "    '''\n",
    "    Fuction plota grid and calls the plot_confusion_matrix function\n",
    "    to plot two confusion matrices. One for the tarin set and another\n",
    "    for the test set bbbbbbbbbbb+           ?????????????????????\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: sklearn confusion matrix\n",
    "    classes: numpy 1D array containing all unique class names\n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    >>>> plot_confusion_normal(xg_model, train_x, train_y)\n",
    "    >>>> plot_confusion_normal(rf_model, train_x, train_y)\n",
    "    '''\n",
    "\n",
    "    # Set the plot size\n",
    "    rcParams['figure.figsize'] = (30.0, 22.5)\n",
    "\n",
    "    # Set up grid\n",
    "    plt.figure()\n",
    "    fig = gridspec.GridSpec(3, 3)\n",
    "    grid_length = list(range(1, 3))\n",
    "    tuple_grid = [(i, j) for i in grid_length for j in grid_length]\n",
    "\n",
    "    # Plot Training Confusion Matrix\n",
    "    plt.subplot2grid((3, 3), (0, 0))\n",
    "    cm = confusion_matrix(train_y, model.predict(train_x))\n",
    "    plot_confusion_matrix(\n",
    "        cm,\n",
    "        classes=classes,\n",
    "        normalize=True,\n",
    "        title=name.capitalize() + ': Train Set',\n",
    "        cmap=cmap)\n",
    "\n",
    "    # Plot Testing Confusion Matrix\n",
    "    plt.subplot2grid((3, 3), (0, 1))\n",
    "    cm = confusion_matrix(test_y, model.predict(test_x))\n",
    "    plot_confusion_matrix(\n",
    "        cm,\n",
    "        classes=classes,\n",
    "        normalize=True,\n",
    "        title=name.capitalize() + ': Test Set',\n",
    "        cmap=cmap)\n",
    "\n",
    "    return None        \n",
    "\n",
    "\n",
    "def plot_confusion_neural(model, classes, train_x, train_y, \n",
    "                          test_x, test_y, cmap=plt.cm.Oranges):\n",
    "    '''\n",
    "    Funtion to plot a grid and calls the plot_confusion_matrix function\n",
    "    to plot two confusion matrices. One for the tarin set and another\n",
    "    for the test set. This function includes a sigmoid function that rounds\n",
    "    networks prediction before plotting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: sklearn confusion matrix\n",
    "    classes: numpy 1D array containing all unique class names\n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    >>>> plot_confusion_neural(nn_model, train_x, train_y)\n",
    "    >>>> plot_confusion_neural(autoencoder, train_x, train_y)\n",
    "    '''\n",
    "\n",
    "    # Set the plot size\n",
    "    rcParams['figure.figsize'] = (30.0, 22.5)\n",
    "\n",
    "    # Set up grid\n",
    "    plt.figure()\n",
    "    fig = gridspec.GridSpec(3, 3)\n",
    "    grid_length = list(range(1, 3))\n",
    "    tuple_grid = [(i, j) for i in grid_length for j in grid_length]\n",
    "\n",
    "    # Plot Training Confusion Matrix\n",
    "    plt.subplot2grid((3, 3), (0, 0))\n",
    "    cm = confusion_matrix(train_y, model.predict(train_x))\n",
    "    plot_confusion_matrix(\n",
    "        cm,\n",
    "        classes,\n",
    "        fontsize=25,\n",
    "        normalize=True,\n",
    "        title=model.name.capitalize() + ': Train Set',\n",
    "        cmap=cmap)\n",
    "\n",
    "    # Plot Testing Confusion Matrix\n",
    "    plt.subplot2grid((3, 3), (0, 1))\n",
    "    cm = confusion_matrix(test_y, (model.predict(test_x)))\n",
    "    plot_confusion_matrix(\n",
    "        cm,\n",
    "        classes,\n",
    "        fontsize=25,\n",
    "        normalize=True,\n",
    "        title=model.name.capitalize() + ': Test Set',\n",
    "        cmap=cmap)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def target_to_anon(array):\n",
    "    '''\n",
    "    Converts prediction in the \n",
    "    0/1 standard format to 1/-1 anomoly format for every\n",
    "    value in the array\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    array: numpy array containing only +1/1\n",
    "\n",
    "    Exmaples\n",
    "    ---------\n",
    "    >>>> anon_to_targets([1,1,,1,1,-1,1,-1,1])\n",
    "    '''\n",
    "    array = [1 if i == 0 else -1 for i in array]\n",
    "    array = np.array(array).reshape(1,-1)[0]\n",
    "    return array\n",
    "\n",
    "\n",
    "def read_csv(path: str, lower=True) -> pd.DataFrame:\n",
    "    '''Read in csv data return dataframe after lowering all columns name\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: Absolulte or Relative Path to csv data\n",
    "    \n",
    "    '''\n",
    "    df = pd.read_csv('paysim.csv')\n",
    "    if lower == True:\n",
    "        df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "# Customer summary stastitics dataframe\n",
    "def sum_stat(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Plot the summary statitic of a dataframe. The statistics \n",
    "    include the normal describe statistics as well as additional\n",
    "    median value, and counts on the number of unique values and\n",
    "    null values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df: A pandas dataframes of datate\n",
    "    '''\n",
    "    \n",
    "    sum_df = pd.concat([df.describe(), \n",
    "           pd.DataFrame(df.nunique(), columns=['nuniques']).T,\n",
    "           pd.DataFrame(np.sum(df.isnull(), axis =0), columns=['isnull']).T],\n",
    "           axis=0)\n",
    "    return sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import paysim data\n",
    "sdf = read_csv('paysim.csv')\n",
    "sdf = sdf.rename(columns={'isfraud':'target', 'oldbalanceorg':'oldbalanceorig'})\n",
    "\n",
    "# Create a holdout dataset with 50% of the data. 3 milliion+ rows each.\n",
    "holdout_index = np.random.choice(np.arange(0,sdf.shape[0]), size=int(sdf.shape[0]*0.75),replace=False)\n",
    "sdf_holdout = sdf[sdf.index.isin(holdout_index)]\n",
    "sdf = sdf[~sdf.index.isin(holdout_index)]\n",
    "sdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all object colunms to categorical codes\n",
    "sdf.type = sdf.type.astype('category').cat.codes\n",
    "sdf.nameorig = sdf.nameorig.astype('category').cat.codes\n",
    "sdf.namedest = sdf.namedest.astype('category').cat.codes\n",
    "\n",
    "# Drop is flagged false column (data leak) and new balance (high correlation) feature\n",
    "sdf = sdf.drop(['isflaggedfraud'], axis=1)\n",
    "\n",
    "# Concatenate one-hot encoded type features\n",
    "sdf = pd.concat([sdf,pd.get_dummies(sdf.type, 'type', drop_first=True)], axis=1).drop('type',axis=1)\n",
    "print(sdf.head(4))\n",
    "sdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruturr dataframes as nupmy arrays\n",
    "X = sdf.drop('target', axis=1).values\n",
    "y = sdf.target.values\n",
    "\n",
    "# Train-test split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Compute Sample Weights\n",
    "weights = compute_sample_weight(class_weight='balanced', y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a new default figure size for plotting\n",
    "rcParams['figure.figsize'] = (30.0, 10.0)\n",
    "\n",
    "# Print the contaminatin rate of the trainin dataset\n",
    "contamination_rate = (sdf['target'].value_counts()/sdf['target'].count())[1]\n",
    "print('Training Contamination Rate:',contamination_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#if_pipeline = joblib.load('Models/fraud_if_pipeline.sav')\n",
    "if_pipeline = make_pipeline(PCA(n_components=10),StandardScaler(), \n",
    "                            IsolationForest(n_jobs=-1,\n",
    "                                contamination=contamination_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save Pipeline\n",
    "joblib.dump(if_pipeline, 'Models/fraud_if_pipeline_a.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run some cross validation on the pipeline\n",
    "if_scores = cross_validate(if_pipeline,X_train,\n",
    "                           target_to_anon(y_train),\n",
    "                           cv=5, \n",
    "                           scoring=['accuracy','precision','recall',\n",
    "                                    'f1','roc_auc'],\n",
    "                           fit_params={'isolationforest__sample_weight':weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if_pipeline.fit(X_train,y_train, **{'isolationforest__sample_weight':weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if_pred = if_pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save Pipeline\n",
    "joblib.dump(if_pipeline, 'Models/fraud_if_pipeline_b.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_confusion_anomoly(model=if_pipeline, classes=[0,1], \n",
    "                      name = 'Isolation Forest Pipeline',\n",
    "                      train_x=X_train,\n",
    "                      test_x=X_test,\n",
    "                      train_y=y_train, test_y=y_test,\n",
    "                       cmap= plt.cm.PuRd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View if model Scores\n",
    "#if_score_df = pd.DataFrame(if_scores).T\n",
    "#if_score_df['Mean'] = if_score_df.mean(axis=1)\n",
    "#if_score_df['Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an Isolation Forest Pipeline\n",
    "#if_pipeline = make_pipeline(PCA(n_components=10),StandardScaler(), \n",
    "#                            IsolationForest(n_jobs=-1,\n",
    "#                                contamination=contamination_rate))\n",
    "\n",
    "# Run some cross validation on the pipeline\n",
    "#if_scores = cross_validate(if_pipeline,X_train,\n",
    "#                           target_to_anon(y_train),\n",
    "#                           cv=5, \n",
    "#                           scoring=['accuracy','precision','recall',\n",
    "#                                    'f1','roc_auc'],\n",
    "#                           fit_params={'isolationforest__sample_weight':weights})\n",
    "\n",
    "# Fit the pipline and return predictions\n",
    "#if_pipeline.fit(X_train,y_train, **{'isolationforest__sample_weight':weights})\n",
    "#if_pred = if_pipeline.predict(X_train)\n",
    "\n",
    "# Save Pipeline\n",
    "#joblib.dump(if_pipeline, 'Models/fraud_if_pipeline.sav')\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "#plot_confusion_anomoly(model=if_pipeline, classes=[0,1], \n",
    "#                      name = 'Isolation Forest Pipeline',\n",
    "#                      train_x=X_train,\n",
    "#                      test_x=X_test,\n",
    "#                      train_y=y_train, test_y=y_test,\n",
    "#                       cmap= plt.cm.PuRd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Encode all object colunms to categorical codes\n",
    "#sdf_holdout.type = sdf_holdout.type.astype('category').cat.codes\n",
    "#sdf_holdout.nameorig = sdf_holdout.nameorig.astype('category').cat.codes\n",
    "#sdf_holdout.namedest = sdf_holdout.namedest.astype('category').cat.codes\n",
    "\n",
    "# Drop is flagged false column\n",
    "#sdf_holdout = sdf_holdout.drop('isflaggedfraud', axis=1)\n",
    "\n",
    "# Concatenate one-hot encoded type features\n",
    "#sdf_holdout = pd.concat([sdf_holdout,pd.get_dummies(sdf_holdout.type, 'type', drop_first=True)], axis=1).drop('type',axis=1)\n",
    "\n",
    "#X_holdout = sdf_holdout.drop('target', axis=1).values\n",
    "#y_holdout = sdf_holdout.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#ee_hold = ee_pipeline.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#print('ee Pipeline ROC AUC Score:',roc_auc_score(y_holdout, ee_hold))\n",
    "#print('if Pipeline ROC AUC Score:',roc_auc_score(y_test, if_pipeline.predict(X_test)))\n",
    "#print('ee Pipeline ROC AUC Score:',precision_score(y_test, ee_pipeline.predict(X_test)))\n",
    "#print('ee Pipeline ROC AUC Score:',recall_score(y_test, ee_pipeline.predict(X_test)))\n",
    "#print('if Pipeline ROC AUC Score:',roc_auc_score(y_train, if_pipeline.predict(X_train)))\n",
    "#print('ee Pipeline f1 Score:',f1_score(y_test, ee_pipeline.predict(X_test)))\n",
    "#print('ee Pipeline f1 Score:',f1_score(y_train, ee_pipeline.predict(X_train)))\n",
    "#print('ee Pipeline F1 Score:',f1_score(y_holdout, ee_hold), '\\n')\n",
    "#print('ee Pipeline ROC AUC Score:',roc_auc_score(y_holdout, ee_pipline.predict(X_holdout)))\n",
    "#print('ee Pipeline F1 Score:',f1_score(y_holdout, ee_pipline.predict(X_holdout)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
